# predict_all_stations.py

import sys
import subprocess
from pathlib import Path
import mlflow
from mlflow.tracking import MlflowClient
import numpy as np
import pandas as pd
import joblib

BASE_DIR = Path(__file__).resolve().parent
DATA_DIR = BASE_DIR / "data" / "processed"   # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏≤‡∏Å DATA_PATH ‡πÄ‡∏õ‡πá‡∏ô DATA_DIR
PRED_DIR = BASE_DIR / "data" / "predictions"
PRED_DIR.mkdir(parents=True, exist_ok=True)

MODEL_NAME = "aqi_best_model"
TARGET_COL = "aqi_next1h"


def get_latest_model_uri(model_name: str) -> str:
    """‡∏î‡∏∂‡∏á model version ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å Model Registry"""
    client = MlflowClient()

    # list versions ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ô‡∏µ‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    versions = client.search_model_versions(f"name='{model_name}'")

    if not versions:
        raise ValueError(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ä‡∏∑‡πà‡∏≠ '{model_name}' ‡πÉ‡∏ô Model Registry")

    # sort ‡∏ï‡∏≤‡∏° version number (string ‚Üí int)
    versions_sorted = sorted(versions, key=lambda v: int(v.version), reverse=True)

    latest_version = versions_sorted[0].version
    print(f"‚úî ‡πÉ‡∏ä‡πâ model version ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î = {latest_version}")

    return f"models:/{model_name}/{latest_version}"


def find_latest_dataset_path() -> Path:
    """
    ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå training/feature dataset ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å DATA_DIR
    pattern: aqi_lagged_SEA_YYYYMMDD_HHMMSS.csv

    ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏ö‡∏ö‡∏°‡∏µ timestamp ‡∏à‡∏∞‡∏•‡∏≠‡∏á‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Å‡πà‡∏≤ aqi_lagged_SEA.csv ‡πÄ‡∏õ‡πá‡∏ô fallback
    """
    pattern = "aqi_lagged_SEA_*.csv"
    files = sorted(DATA_DIR.glob(pattern))

    if files:
        latest = files[-1]  # YYYYMMDD_HHMMSS ‡∏ó‡∏≥‡πÉ‡∏´‡πâ sort ‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏î‡πâ‡∏ï‡∏£‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß
        print(f"üîç [PREDICT] ‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå dataset {len(files)} ‡πÑ‡∏ü‡∏•‡πå, ‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: {latest.name}")
        return latest

    legacy = DATA_DIR / "aqi_lagged_SEA.csv"
    if legacy.exists():
        print(f"‚ö†Ô∏è [PREDICT] ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏ö‡∏ö‡∏°‡∏µ timestamp ‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå legacy ‡πÅ‡∏ó‡∏ô: {legacy.name}")
        return legacy

    raise FileNotFoundError(
        f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå dataset ‡πÉ‡∏ô {DATA_DIR} "
        f"(‡∏ó‡∏±‡πâ‡∏á pattern aqi_lagged_SEA_*.csv ‡πÅ‡∏•‡∏∞ aqi_lagged_SEA.csv)"
    )


def load_latest_per_station(path: Path) -> pd.DataFrame:
    if not path.exists():
        raise FileNotFoundError(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå processed data ‡∏ó‡∏µ‡πà {path}")

    df = pd.read_csv(path)
    print(f"‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å {path}, shape = {df.shape}")

    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏ß‡∏•‡∏≤
    if "station_time" in df.columns:
        df["station_time"] = pd.to_datetime(df["station_time"], errors="coerce")

    # ‡∏•‡∏ö NaN
    df = df.dropna()
    print(f"‡∏´‡∏•‡∏±‡∏á dropna ‡πÅ‡∏•‡πâ‡∏ß shape = {df.shape}")

    # sort ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏ñ‡∏ß‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ï‡πà‡∏≠ station
    df = df.sort_values(["station_idx", "station_time"])
    latest = df.groupby("station_idx", as_index=False).tail(1).reset_index(drop=True)
    print(f"‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÅ‡∏ñ‡∏ß‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ ‡πÄ‡∏´‡∏•‡∏∑‡∏≠ {latest.shape[0]} ‡πÅ‡∏ñ‡∏ß")
    return latest


def make_feature_matrix(df: pd.DataFrame):
    cols_to_drop = {
        TARGET_COL,
        "station_idx",
        "station_name",
        "station_time",
    }

    cols_to_use = [c for c in df.columns if c not in cols_to_drop]
    X = df[cols_to_use]

    # ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡πà‡∏≤‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
    X = X.select_dtypes(include=[np.number])

    print(f"‡πÉ‡∏ä‡πâ features ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô {X.shape[1]} ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå: {list(X.columns)}")
    return X


def get_latest_model_path() -> Path:
    """Find the latest model file in the best_models directory."""
    model_files = sorted((BASE_DIR / "best_models").glob("*.pkl"))

    if not model_files:
        raise FileNotFoundError("No model files found in the best_models directory.")

    latest_model = model_files[-1]  # The most recent model based on naming convention
    print(f"‚úî Using the latest model: {latest_model.name}")
    return latest_model


def main():
    # 0) ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ ‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡∏£‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏î‡πâ‡∏ß‡∏¢ train.py)
    try:
        model_path = get_latest_model_path()
    except FileNotFoundError:
        print("‚ö† No models found in 'best_models' -> Running train.py to create the first model...")
        subprocess.run([sys.executable, str(BASE_DIR / "train.py")], check=True)
        # ‡∏•‡∏≠‡∏á‡∏î‡∏∂‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
        model_path = get_latest_model_path()

    # 1) ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå dataset ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î ‡πÅ‡∏•‡πâ‡∏ß‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ
    data_path = find_latest_dataset_path()
    df_latest = load_latest_per_station(data_path)

    # 2) ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° feature matrix
    X = make_feature_matrix(df_latest)

    # 3) ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å best_models directory
    print(f"Loading model from: {model_path}")
    model = joblib.load(model_path)

    # 4) predict
    preds = model.predict(X)

    # 5) Export ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    out = df_latest[["station_idx", "station_name", "lat", "lon", "station_time"]].copy()
    out["pred_aqi_next1h"] = preds

    out_path = PRED_DIR / "aqi_next1h_latest_stations.csv"
    out.to_csv(out_path, index=False, encoding="utf-8-sig")

    print(f"\n‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå AQI ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡∏ñ‡∏±‡∏î‡πÑ‡∏õ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡∏ó‡∏µ‡πà: {out_path}")
    print("‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏´‡∏±‡∏ß‡∏ï‡∏≤‡∏£‡∏≤‡∏á:")
    print(out.head())


if __name__ == "__main__":
    main()