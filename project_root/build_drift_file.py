# build_drift_file.py
# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö data drift detection ‡∏à‡∏≤‡∏Å clean daily data

from pathlib import Path
import pandas as pd
import numpy as np

BASE_DIR = Path(__file__).resolve().parent

DAILY_DIR = BASE_DIR / "data" / "clean" / "daily"
DRIFT_DIR = BASE_DIR / "data" / "drift"
DRIFT_DIR.mkdir(parents=True, exist_ok=True)


def load_all_daily() -> pd.DataFrame:
    """‡πÇ‡∏´‡∏•‡∏î daily data ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
    files = sorted(DAILY_DIR.glob("waqi_daily_SEA_*.csv"))
    if not files:
        raise FileNotFoundError(f"‡πÑ‡∏°‡πà‡∏û‡∏ö daily files ‡πÉ‡∏ô {DAILY_DIR}")

    dfs = []
    for f in files:
        print(f"[DRIFT] ‡πÇ‡∏´‡∏•‡∏î {f.name}")
        df = pd.read_csv(f)
        dfs.append(df)

    df_all = pd.concat(dfs, ignore_index=True)
    print(f"‡∏£‡∏ß‡∏° daily data ‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(df_all)} ‡πÅ‡∏ñ‡∏ß")
    return df_all


def prepare_drift_features(df: pd.DataFrame) -> pd.DataFrame:
    """‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° features ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö drift detection"""
    df = df.copy()

    # ‡πÅ‡∏õ‡∏•‡∏á datetime columns
    if "station_time" in df.columns:
        df["station_time"] = pd.to_datetime(df["station_time"], errors="coerce")
    if "date" in df.columns:
        df["date"] = pd.to_datetime(df["date"], errors="coerce")

    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å numeric features ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡∏ï‡∏≤‡∏° train.py)
    # ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà feature ‡∏≠‡∏≠‡∏Å
    cols_to_drop = {
        "station_idx",
        "station_name",
        "station_url",
        "station_time",
        "station_tz",
        "station_unix",
        "ingested_at_utc",
        "global_uid",
        "global_aqi_snapshot",
        "global_snapshot_utc",
        "dominentpol",  # categorical
    }

    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞ numeric columns
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    
    # ‡∏•‡∏ö columns ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
    feature_cols = [c for c in numeric_cols if c not in cols_to_drop]
    
    # ‡πÅ‡∏ö‡πà‡∏á features ‡πÄ‡∏õ‡πá‡∏ô core (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç) ‡πÅ‡∏•‡∏∞ optional (‡∏≠‡∏≤‡∏à‡∏°‡∏µ missing)
    core_features = ["lat", "lon", "aqi", "pm25", "pm10", "t", "h", "p"]
    core_features = [c for c in core_features if c in feature_cols]
    
    optional_features = [c for c in feature_cols if c not in core_features]
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏° date ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö tracking (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
    metadata_cols = []
    if "date" in df.columns:
        metadata_cols.append("date")

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á dataframe ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö drift
    drift_df = df[feature_cols + metadata_cols].copy()

    # ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ NaN ‡πÉ‡∏ô core features ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô (‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÉ‡∏´‡πâ optional features ‡∏°‡∏µ missing)
    drift_df = drift_df.dropna(subset=core_features)

    # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö optional features ‡∏ó‡∏µ‡πà‡∏°‡∏µ missing ‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ (>80%), ‡∏•‡∏ö‡∏≠‡∏≠‡∏Å
    cols_to_keep = []
    for col in feature_cols:
        if col in core_features:
            cols_to_keep.append(col)
        else:
            missing_pct = drift_df[col].isnull().sum() / len(drift_df)
            if missing_pct < 0.8:  # ‡∏ñ‡πâ‡∏≤ missing < 80% ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ
                cols_to_keep.append(col)
            else:
                print(f"   - ‡∏•‡∏ö {col} (missing {missing_pct*100:.1f}%)")

    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞ columns ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
    final_cols = [c for c in cols_to_keep + metadata_cols if c in drift_df.columns]
    drift_df = drift_df[final_cols].copy()

    print(f"‡πÉ‡∏ä‡πâ features ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô {len(cols_to_keep)} ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå")
    print(f"   Core features: {core_features}")
    print(f"   Optional features: {[c for c in cols_to_keep if c not in core_features]}")
    print(f"‡∏´‡∏•‡∏±‡∏á dropna (core features) ‡πÅ‡∏•‡πâ‡∏ß shape = {drift_df.shape}")

    return drift_df


def main():
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö data drift detection"""
    print("=" * 60)
    print("‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Data Drift Detection")
    print("=" * 60)

    # ‡πÇ‡∏´‡∏•‡∏î daily data
    df_all = load_all_daily()

    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° features ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö drift
    df_drift = prepare_drift_features(df_all)

    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå
    output_path = DRIFT_DIR / "waqi_drift_reference.csv"
    df_drift.to_csv(output_path, index=False)
    
    print(f"\nüéâ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå drift reference ‡∏ó‡∏µ‡πà: {output_path}")
    print(f"   Shape: {df_drift.shape}")
    print(f"   Columns: {list(df_drift.columns)}")
    print(f"\nüí° ‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô reference dataset ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Evidently AI")


if __name__ == "__main__":
    main()

