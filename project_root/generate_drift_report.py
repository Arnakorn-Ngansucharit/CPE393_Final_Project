# generate_drift_report.py
# ‡∏™‡∏£‡πâ‡∏≤‡∏á Evidently AI report ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö data drift detection

from pathlib import Path
import pandas as pd
from datetime import datetime

try:
    from evidently import Report
    from evidently.presets import DataDriftPreset
except ImportError:
    print("‚ö†Ô∏è  Evidently AI ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á")
    print("   ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏î‡πâ‡∏ß‡∏¢: pip install evidently")
    raise

BASE_DIR = Path(__file__).resolve().parent

DRIFT_DIR = BASE_DIR / "data" / "drift"
DRIFT_DIR.mkdir(parents=True, exist_ok=True)

REPORT_DIR = BASE_DIR / "data" / "drift" / "reports"
REPORT_DIR.mkdir(parents=True, exist_ok=True)

TRAINED_DATA_DIR = BASE_DIR / "data" / "trained_data"
PROCESSED_DIR = BASE_DIR / "data" / "processed"


def load_reference_data() -> pd.DataFrame:
    """
    ‡πÇ‡∏´‡∏•‡∏î reference dataset ‡∏à‡∏≤‡∏Å trained_data
    ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå preprocessed_dataset_*.csv ‡∏´‡∏£‡∏∑‡∏≠ trained_data_*.csv ‡πÉ‡∏ô data/trained_data/
    ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ training dataset ‡∏à‡∏≤‡∏Å data/processed/aqi_lagged_SEA_*.csv
    """
    # ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô trained_data/ ‡∏Å‡πà‡∏≠‡∏ô
    reference_file = None
    
    if TRAINED_DATA_DIR.exists():
        # ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå preprocessed_dataset_*.csv
        files_preprocessed = sorted(TRAINED_DATA_DIR.glob("preprocessed_dataset_*.csv"), reverse=True)
        # ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå trained_data_*.csv
        files_trained = sorted(TRAINED_DATA_DIR.glob("trained_data_*.csv"), reverse=True)
        
        all_trained_files = files_preprocessed + files_trained
        if all_trained_files:
            reference_file = all_trained_files[0]
            print(f"[DRIFT] ‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå trained data: {reference_file.name}")
    
    # Fallback: ‡πÉ‡∏ä‡πâ training dataset ‡∏à‡∏≤‡∏Å processed/
    if reference_file is None:
        if PROCESSED_DIR.exists():
            files_processed = sorted(PROCESSED_DIR.glob("aqi_lagged_SEA_*.csv"), reverse=True)
            if files_processed:
                reference_file = files_processed[0]
                print(f"[DRIFT] ‡πÉ‡∏ä‡πâ training dataset ‡∏à‡∏≤‡∏Å processed/: {reference_file.name}")
    
    if reference_file is None:
        raise FileNotFoundError(
            f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå trained data ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô reference\n"
            f"   ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÉ‡∏ô: {TRAINED_DATA_DIR} (preprocessed_dataset_*.csv ‡∏´‡∏£‡∏∑‡∏≠ trained_data_*.csv)\n"
            f"   ‡∏´‡∏£‡∏∑‡∏≠: {PROCESSED_DIR} (aqi_lagged_SEA_*.csv)\n"
            f"‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏±‡∏ô train.py ‡∏´‡∏£‡∏∑‡∏≠ build_training_dataset.py ‡∏Å‡πà‡∏≠‡∏ô"
        )
    
    print(f"[DRIFT] ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå reference (trained data): {reference_file.relative_to(BASE_DIR)}")
    df = pd.read_csv(reference_file)
    
    # ‡πÅ‡∏õ‡∏•‡∏á date column ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
    if "date" in df.columns:
        df["date"] = pd.to_datetime(df["date"], errors="coerce")
    if "station_time" in df.columns:
        df["station_time"] = pd.to_datetime(df["station_time"], errors="coerce")
    
    print(f"‡πÇ‡∏´‡∏•‡∏î reference data (trained data): {df.shape}")
    return df


def load_current_data() -> pd.DataFrame:
    """
    ‡πÇ‡∏´‡∏•‡∏î current/production data ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå hourly ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
    ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå waqi_hourly_SEA_* ‡πÅ‡∏•‡∏∞ waqi_cleaned_* ‡πÉ‡∏ô‡∏ó‡∏∏‡∏Å subfolder
    """
    hourly_dir = BASE_DIR / "data" / "clean" / "hourly"
    if not hourly_dir.exists():
        raise FileNotFoundError(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå {hourly_dir}")

    # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á waqi_hourly_SEA_* ‡πÅ‡∏•‡∏∞ waqi_cleaned_* ‡πÉ‡∏ô‡∏ó‡∏∏‡∏Å subfolder
    files_hourly = list(hourly_dir.rglob("waqi_hourly_SEA_*.csv"))
    files_cleaned = list(hourly_dir.rglob("waqi_cleaned_*.csv"))
    all_files = files_hourly + files_cleaned
    
    if not all_files:
        raise FileNotFoundError(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå hourly data ‡πÉ‡∏ô {hourly_dir}")

    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (mtime)
    all_files.sort(key=lambda f: f.stat().st_mtime, reverse=True)
    latest_file = all_files[0]
    
    print(f"[DRIFT] ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå hourly ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: {latest_file.name}")
    print(f"       Path: {latest_file.relative_to(BASE_DIR)}")
    df_current = pd.read_csv(latest_file)

    # ‡πÅ‡∏õ‡∏•‡∏á date column ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
    if "date" in df_current.columns:
        df_current["date"] = pd.to_datetime(df_current["date"], errors="coerce")

    print(f"‡πÇ‡∏´‡∏•‡∏î current data: {df_current.shape}")
    return df_current


def prepare_data_for_evidently(df_ref: pd.DataFrame, df_current: pd.DataFrame) -> tuple:
    """
    ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Evidently
    Evidently ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ columns ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏°‡∏µ date column (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô datetime feature)
    """
    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞ numeric columns (‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏° date)
    numeric_cols = df_ref.select_dtypes(include=['float64', 'int64']).columns.tolist()
    
    # ‡∏•‡∏ö date ‡∏≠‡∏≠‡∏Å‡∏ñ‡πâ‡∏≤‡∏°‡∏µ (‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÄ‡∏õ‡πá‡∏ô metadata)
    if "date" in numeric_cols:
        numeric_cols.remove("date")
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ columns ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô
    common_cols = [c for c in numeric_cols if c in df_current.columns]
    
    if len(common_cols) != len(numeric_cols):
        missing = set(numeric_cols) - set(common_cols)
        print(f"‚ö†Ô∏è  Warning: columns ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô - ‡∏Ç‡∏≤‡∏î: {missing}")
    
    df_ref_clean = df_ref[common_cols].copy()
    df_current_clean = df_current[common_cols].copy()
    
    # ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ NaN (Evidently ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà clean)
    df_ref_clean = df_ref_clean.dropna()
    df_current_clean = df_current_clean.dropna()
    
    print(f"Reference data (clean): {df_ref_clean.shape}")
    print(f"Current data (clean): {df_current_clean.shape}")
    print(f"Features: {list(common_cols)}")
    
    return df_ref_clean, df_current_clean


def generate_drift_report(df_ref: pd.DataFrame, df_current: pd.DataFrame):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á Evidently data drift report (Evidently 0.7.x API)"""
    print("\n" + "=" * 60)
    print("‡∏™‡∏£‡πâ‡∏≤‡∏á Evidently Data Drift Report")
    print("=" * 60)
    
    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    df_ref_clean, df_current_clean = prepare_data_for_evidently(df_ref, df_current)
    
    if len(df_ref_clean) == 0 or len(df_current_clean) == 0:
        raise ValueError("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á report")
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î schema (numeric features)
    numeric_features = [c for c in df_ref_clean.columns if df_ref_clean[c].dtype in ['float64', 'int64']]
    
    print(f"\nüìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á report...")
    print(f"   Numeric features: {len(numeric_features)}")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á report
    report = Report(metrics=[DataDriftPreset()])
    
    # ‡∏£‡∏±‡∏ô report ‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏ö snapshot (Evidently 0.7.x: column_mapping ‡∏™‡πà‡∏á‡πÉ‡∏ô run(), ‡πÅ‡∏•‡∏∞ run() ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ snapshot)
    snapshot = report.run(
        reference_data=df_ref_clean,
        current_data=df_current_clean,
    )
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å report (Evidently 0.7.x: save_html ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô snapshot)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_path = REPORT_DIR / f"drift_report_{timestamp}.html"
    
    snapshot.save_html(str(report_path))
    
    print(f"\n‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å report ‡∏ó‡∏µ‡πà: {report_path}")
    
    # ‡πÅ‡∏™‡∏î‡∏á summary
    print("\n" + "=" * 60)
    print("Report Summary")
    print("=" * 60)
    
    # ‡∏î‡∏∂‡∏á metrics ‡∏à‡∏≤‡∏Å snapshot dict
    try:
        metrics_dict = snapshot.dict()
        metrics = metrics_dict.get('metrics', [])

        drift_metric = next(
            (m for m in metrics if str(m.get('metric_name', '')).startswith('DriftedColumnsCount')),
            None,
        )

        if drift_metric:
            value = drift_metric.get('value', {})
            config = drift_metric.get('config', {})
            drift_share = float(value.get('share', 0))
            num_drifted = int(value.get('count', 0))
            total_features = len(numeric_features)
            threshold = float(config.get('drift_share', 0.5))
            drift_detected = drift_share >= threshold

            print(f"Dataset Drift Detected: {drift_detected}")
            print(f"Drift Share: {drift_share:.2f} (threshold {threshold:.2f})")
            print(f"Drifted Features: {num_drifted} / {total_features}")
        else:
            print("‚ö†Ô∏è  ‡πÑ‡∏°‡πà‡∏û‡∏ö metric DriftedColumnsCount ‡πÉ‡∏ô snapshot.dict()")
    except Exception as e:
        print(f"‚ö†Ô∏è  ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á summary ‡πÑ‡∏î‡πâ: {e}")
        print("   ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÉ‡∏ô HTML report ‡πÅ‡∏ó‡∏ô")
    
    print(f"\nüí° ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå {report_path} ‡πÉ‡∏ô browser ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î")
    
    return report_path


def main():
    """Main function"""
    try:
        # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        print("=" * 60)
        print("Evidently AI - Data Drift Report Generator")
        print("=" * 60)
        
        df_ref = load_reference_data()
        df_current = load_current_data()
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á report
        report_path = generate_drift_report(df_ref, df_current)
        
        print("\nüéâ ‡∏™‡∏£‡πâ‡∏≤‡∏á drift report ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß!")
        print(f"   Report: {report_path}")
        
    except FileNotFoundError as e:
        print(f"\n‚ùå Error: {e}")
        print("\nüí° ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:")
        print("   1. ‡∏£‡∏±‡∏ô train.py ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á trained data")
        print("   2. ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏±‡∏ô build_training_dataset.py ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á training dataset")
        print("   3. ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    except ImportError as e:
        print(f"\n‚ùå Error: {e}")
        print("\nüí° ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:")
        print("   pip install evidently")
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

