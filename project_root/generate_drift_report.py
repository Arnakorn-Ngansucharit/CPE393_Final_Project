# generate_drift_report.py
# ‡∏™‡∏£‡πâ‡∏≤‡∏á Evidently AI report ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö data drift detection

from pathlib import Path
import pandas as pd
from datetime import datetime

try:
    from evidently.report import Report
    from evidently.metric_preset import DataDriftPreset
    from evidently import ColumnMapping
except ImportError:
    print("‚ö†Ô∏è  Evidently AI ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á")
    print("   ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏î‡πâ‡∏ß‡∏¢: pip install evidently")
    raise

BASE_DIR = Path(__file__).resolve().parent

DRIFT_DIR = BASE_DIR / "data" / "drift"
DRIFT_DIR.mkdir(parents=True, exist_ok=True)

REPORT_DIR = BASE_DIR / "data" / "drift" / "reports"
REPORT_DIR.mkdir(parents=True, exist_ok=True)

REFERENCE_PATH = DRIFT_DIR / "waqi_drift_reference.csv"


def load_reference_data() -> pd.DataFrame:
    """‡πÇ‡∏´‡∏•‡∏î reference dataset"""
    if not REFERENCE_PATH.exists():
        raise FileNotFoundError(
            f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå reference ‡∏ó‡∏µ‡πà {REFERENCE_PATH}\n"
            f"‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏±‡∏ô build_drift_file.py ‡∏Å‡πà‡∏≠‡∏ô"
        )
    
    df = pd.read_csv(REFERENCE_PATH)
    
    # ‡πÅ‡∏õ‡∏•‡∏á date column ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
    if "date" in df.columns:
        df["date"] = pd.to_datetime(df["date"], errors="coerce")
    
    print(f"‡πÇ‡∏´‡∏•‡∏î reference data: {df.shape}")
    return df


def load_current_data() -> pd.DataFrame:
    """
    ‡πÇ‡∏´‡∏•‡∏î current/production data ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå hourly ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
    """
    hourly_dir = BASE_DIR / "data" / "clean" / "hourly"
    if not hourly_dir.exists():
        raise FileNotFoundError(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå {hourly_dir}")

    files = sorted(hourly_dir.glob("waqi_hourly_SEA_*.csv"), reverse=True)
    if not files:
        raise FileNotFoundError(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå hourly data ‡πÉ‡∏ô {hourly_dir}")

    latest_file = files[0]
    print(f"[DRIFT] ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå hourly ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: {latest_file.name}")
    df_current = pd.read_csv(latest_file)

    # ‡πÅ‡∏õ‡∏•‡∏á date column ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
    if "date" in df_current.columns:
        df_current["date"] = pd.to_datetime(df_current["date"], errors="coerce")

    print(f"‡πÇ‡∏´‡∏•‡∏î current data: {df_current.shape}")
    return df_current


def prepare_data_for_evidently(df_ref: pd.DataFrame, df_current: pd.DataFrame) -> tuple:
    """
    ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Evidently
    Evidently ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ columns ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏°‡∏µ date column (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô datetime feature)
    """
    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞ numeric columns (‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏° date)
    numeric_cols = df_ref.select_dtypes(include=['float64', 'int64']).columns.tolist()
    
    # ‡∏•‡∏ö date ‡∏≠‡∏≠‡∏Å‡∏ñ‡πâ‡∏≤‡∏°‡∏µ (‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÄ‡∏õ‡πá‡∏ô metadata)
    if "date" in numeric_cols:
        numeric_cols.remove("date")
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ columns ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô
    common_cols = [c for c in numeric_cols if c in df_current.columns]
    
    if len(common_cols) != len(numeric_cols):
        missing = set(numeric_cols) - set(common_cols)
        print(f"‚ö†Ô∏è  Warning: columns ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô - ‡∏Ç‡∏≤‡∏î: {missing}")
    
    df_ref_clean = df_ref[common_cols].copy()
    df_current_clean = df_current[common_cols].copy()
    
    # ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ NaN (Evidently ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà clean)
    df_ref_clean = df_ref_clean.dropna()
    df_current_clean = df_current_clean.dropna()
    
    print(f"Reference data (clean): {df_ref_clean.shape}")
    print(f"Current data (clean): {df_current_clean.shape}")
    print(f"Features: {list(common_cols)}")
    
    return df_ref_clean, df_current_clean


def generate_drift_report(df_ref: pd.DataFrame, df_current: pd.DataFrame):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á Evidently data drift report"""
    print("\n" + "=" * 60)
    print("‡∏™‡∏£‡πâ‡∏≤‡∏á Evidently Data Drift Report")
    print("=" * 60)
    
    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    df_ref_clean, df_current_clean = prepare_data_for_evidently(df_ref, df_current)
    
    if len(df_ref_clean) == 0 or len(df_current_clean) == 0:
        raise ValueError("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á report")
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î schema (numeric features)
    numeric_features = [c for c in df_ref_clean.columns if df_ref_clean[c].dtype in ['float64', 'int64']]
    
    print(f"\nüìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á report...")
    print(f"   Numeric features: {len(numeric_features)}")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á ColumnMapping
    column_mapping = ColumnMapping()
    column_mapping.numerical_features = numeric_features

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á report
    report = Report(metrics=[DataDriftPreset()])
    
    # ‡∏£‡∏±‡∏ô report
    report.run(reference_data=df_ref_clean, current_data=df_current_clean, column_mapping=column_mapping)
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å report
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_path = REPORT_DIR / f"drift_report_{timestamp}.html"
    
    report.save_html(str(report_path))
    
    print(f"\n‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å report ‡∏ó‡∏µ‡πà: {report_path}")
    
    # ‡πÅ‡∏™‡∏î‡∏á summary
    print("\n" + "=" * 60)
    print("Report Summary")
    print("=" * 60)
    
    # ‡∏î‡∏∂‡∏á metrics ‡∏à‡∏≤‡∏Å json
    try:
        metrics_dict = report.as_dict()
        
        # ‡∏´‡∏≤ data drift metrics
        if 'metrics' in metrics_dict:
            for metric_result in metrics_dict['metrics']:
                if metric_result['metric'] == 'DatasetDriftMetric':
                    result = metric_result.get('result', {})
                    drift_detected = result.get('dataset_drift', False)
                    drift_share = result.get('drift_share', 0)
                    print(f"Dataset Drift Detected: {drift_detected}")
                    print(f"Drift Share: {drift_share:.2f}")
                    
                    num_drifted = result.get('number_of_drifted_columns', 0)
                    total_features = result.get('number_of_columns', 0)
                    print(f"Drifted Features: {num_drifted} / {total_features}")
    except Exception as e:
        print(f"‚ö†Ô∏è  ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á summary ‡πÑ‡∏î‡πâ: {e}")
        print("   ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÉ‡∏ô HTML report ‡πÅ‡∏ó‡∏ô")
    
    print(f"\nüí° ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå {report_path} ‡πÉ‡∏ô browser ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î")
    
    return report_path


def main():
    """Main function"""
    try:
        # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        print("=" * 60)
        print("Evidently AI - Data Drift Report Generator")
        print("=" * 60)
        
        df_ref = load_reference_data()
        df_current = load_current_data()
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á report
        report_path = generate_drift_report(df_ref, df_current)
        
        print("\nüéâ ‡∏™‡∏£‡πâ‡∏≤‡∏á drift report ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß!")
        print(f"   Report: {report_path}")
        
    except FileNotFoundError as e:
        print(f"\n‚ùå Error: {e}")
        print("\nüí° ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:")
        print("   1. ‡∏£‡∏±‡∏ô build_drift_file.py ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á reference dataset")
        print("   2. ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    except ImportError as e:
        print(f"\n‚ùå Error: {e}")
        print("\nüí° ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:")
        print("   pip install evidently")
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

